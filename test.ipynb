{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_idx_images(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        assert magic == 2051, f\"Magic number mismatch, got {magic}\"\n",
    "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        # flat the data to N * 784 matrix and change to float32\n",
    "        images = (data.reshape(num, rows*cols)).astype(np.float32) / 255.0\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_idx_labels(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        assert magic == 2049, f\"Magic number mismatch, got {magic}\"\n",
    "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前向传播函数，得到Z\n",
    "def forward(X: np.ndarray, W: np.ndarray, b: np.ndarray):\n",
    "    Z = X.dot(W) + b\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算损失函数的y_int版本\n",
    "def cross_entropy_from_int(Y_hat: np.ndarray, y_int: np.ndarray, eps: int=1e-12):\n",
    "    # 生成一个y_hat长度的index索引\n",
    "    rows = np.arange(Y_hat.shape[0])\n",
    "    # 使用高级索引，得到y_hat中所有需要得到的值，也就是对应正确答案的概率\n",
    "    p_true = Y_hat[rows, y_int]\n",
    "    # 把所有正确答案加eps求log，然后求负平均值\n",
    "    loss = -np.mean(np.log(p_true + eps))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算损失函数对Zt的导数，作为求得梯度的前提\n",
    "def d_loss_d_Z(Y_hat: np.ndarray, Y_onehot: np.ndarray, B: int):\n",
    "    G = Y_hat.copy()\n",
    "    G -= Y_onehot\n",
    "    G /= B\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax处理，把Z变成概率矩阵\n",
    "def softMax(Z: np.ndarray):\n",
    "    Z_shift = Z - np.max(Z, axis=1, keepdims=True)\n",
    "    exp_Z = np.exp(Z_shift)\n",
    "    probs = exp_Z / np.sum(exp_Z, axis=1, keepdims=True)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.273866, acc = 0.923600\n"
     ]
    }
   ],
   "source": [
    "images_path = \"./t10k-images.idx3-ubyte\"\n",
    "labels_path = \"./t10k-labels.idx1-ubyte\"\n",
    "\n",
    "X = load_idx_images(images_path)\n",
    "Y = load_idx_labels(labels_path)\n",
    "\n",
    "W = np.load(\"./W.npy\")\n",
    "b = np.load(\"./b.npy\")\n",
    "\n",
    "Z = forward(X, W, b)\n",
    "probs = softMax(Z)\n",
    "loss = cross_entropy_from_int(probs, Y)\n",
    "acc = (probs.argmax(axis=1) == Y).mean()\n",
    "print(f\"loss: {loss:4f}, acc = {acc:4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
